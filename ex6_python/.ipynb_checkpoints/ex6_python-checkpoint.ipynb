{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Exercise 6: Support Vector Machines\n",
    "\n",
    "```\n",
    "by Seokkyu Kong\n",
    "Date: 2016-03-28\n",
    "Summary: Coursera 코세라 machine learning 기계학습 강의 연습문제 6번을 Octave에서 Python으로 code migration 한다.\n",
    "```\n",
    "\n",
    "## Introduction \n",
    "\n",
    "이번 연습문제에서는, support vector machines 지지 벡터 머신 (SVMs) 를 사용해서 스팸 분류기를 구축한다. \n",
    "\n",
    "## 1. Support Vector Machines\n",
    "\n",
    "연습문제 전반부에서, 다양한 example 2D datasets을 가지고 지지 벡터 머신을 사용한다. 이들 데이터셋으로 실험하는 것은 SVM이 어떻게 동작하는지와 SVMs에 가우시안 커널을 어떻게 사용하는지에 대한 직관을 얻는데 도움이 될 것이다. 연습문제 후반부에서는 스팸 분류기를 구축하기 위해서 지지 벡터 머신을 사용할 것이다. \n",
    "\n",
    "### 1.1 Example Dataset 1\n",
    "\n",
    "우리는 2D example dataset으로 시작하는데, linear boundary로 분리될 수 있다. 스크립트 ex6.m 은 training data를 plot한다. (그림 1) 이 데이터넷에서, positive examples(+로 표시됨)의 위치와 negative exampels(o로 표시됨)의 위치는 gap에 의해서 표시된 자연스럼 구분을 제시한다. 그런데, 왼쪽 끝에 (0.1, 4.1) 위치에서 이상치 positive example + 가 있음을 주목해라. 이 연습문제의 일부분으로, 이 이상치가 SVM decision boundary에 어떻게 영향을 주는지 보게 될 것이다.\n",
    "\n",
    "연습문제 이 부분에서, SVMs에 서로 다른 C 값을 사용하게 될 것이다. 비공식적으로, __파라미터 C는 잘못 분류된 traininig examples에 대한 penalty를 제어하는 양의 값이다. 값이 큰 C 파라미터는 SVM이 모든 examples를 올바르게 분류하도록 시킨다. C는 1/lambda 와 유사한 역할을 하는데, lambda는 logistic regression을 위해서 이전에 사용했던 regularization 파라미터이다.__\n",
    "\n",
    "ex6.m의 다음 부분에서 SVM 소프트웨어를 이용해서 (C = 1)로 SVM을 훈련시키는데, 우리는 시작하는 코드로 svmTrain.m 을 포함시켰다. \n",
    "\n",
    "C  = 1 일때, SVM은 두 개의 데이터셋 사이에 있는 gap 에 decision boundary를 놓는데 왼쪽 구성에 있는 데이터 포인트는 잘못 분류하고 있음을 볼 수 있다. (그림 2)\n",
    "\n",
    "```\n",
    "Implementation Note: 대부분의 SVM 소프트웨어 패키지들은 (svmTrain.m을 포함해서) 자동적으로 추가적인 feature x0 = 1을 추가한다. 그리고 자동적으로 절편 항목 theta0를 학습하는데 신경을 쓴다. 그래서 traininig data를 SVM 소프트웨어에 전달할 때, 추가 feature인 x0 = 1을 추가할 필요가 없다. 특히, Octave/MATLAB 에서 코드는 traininig examples x ( Rn 에서 동작해야 한다. (x ( Rn+1 이 아니다); 예를 들어 첫번째 exmaple dataset은 x ( R2 이다.\n",
    "```\n",
    "\n",
    "당신의 작업은 이 데이터넷 상에서 서로 다른 C 값을 시도해보는 것이다. 특히, 스크립트 내의 C 값을 C = 100으로 하고 SVM training을 다시 실행해 봐라. C = 100 일때, SVM은 이제 각각의 단일 example을 올바르게 분류하지만, decision boundary는 데이터에 대해서 자연스럽게 맞지 않음을 볼 수 있어야 한다.\n",
    "\n",
    "### 1.2 SVM with Gaussian Kernels\n",
    "\n",
    "연습문제의 이 부분에서, 당신은 non-linear classification을 수행하는 SVMs를 사용하게 된다. 특히, 가우시안 커널을 가진 SVMs을 선형으로 분리될 수 없는 데이터셋 상에 사용할 것이다.\n",
    "\n",
    "#### 1.2.1 Gaussian Kernel\n",
    "\n",
    "SVM으로 non-linear decision boundaries를 찾기 위해서는, 우리는 먼저 Gaussian kernel을 구현할 필요가 있다. __가우시안 커널을 한 쌍의 examples 사이에 \"distance\"를 측정하는 유사도 함수로 생각할 수 있다. 가우시안 커널은 또한 bandwidth 파라미터 sigma로 파라미터화 할 수 있는데 그것은 examples가 멀리 떨어짐에 따라 얼마나 빨리 유사도 메트릭이 감소되는지 (0으로) 결정하는 값이다.__\n",
    "\n",
    "당신은 이제 gaussianKernel.m 을 완성해서 2개의 examples (x(i), x(j)) 사이의 Gaussian kernel을 계산해야 한다. 가우시안 커널 함수는 다음처럼 정의 된다.\n",
    "\n",
    "일단, gaussianKernel.m 함수를 완성하면, 스크립트 ex6.m은 커널 함수를 2개의 제공된 examples에 테스트 하는데 0.324652 값을 기대해야 한다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 코드 작성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1.2.2 Example Dataset 2\n",
    "\n",
    "ex6.m의 다음 부분은 dataset 2를 load하고 plot 할 것이다. (그림 4) 이 그림에서, 당신은 이 데이터셋에 대한 positive와 negative examples를 분리하는 linear boundary가 없음을 볼 수 있다. 어쨌든, SVM과 함께 가우시안 커널을 이용해서 데이터셋에 합리적으로 잘 성능을 낼 수 있는 비선형 decision boundary를 학습할 수 있게 된다. \n",
    "\n",
    "만약 가우시안 함수를 올바르게 구현했다면, ex6.m은 이 데이터셋 상에서 가우시안 커널을 가진 SVM을 훈련시키게 된다.\n",
    "\n",
    "Figure 5: SVM (Gaussian Kernel) Decision Boundary (Example Dataset 2)\n",
    "\n",
    "그림 5는 가우시안 커널을 가진 SVM에 의해 발견된 decision boundary를 보여준다. decision boundary는 대부분의 positive와 negative examples를 올바르게 분리할 수 있고 데이터셋의 contours에 잘 따른다.\n",
    "\n",
    "#### 1.2.3 Example Dataset 3\n",
    "\n",
    "연습문제 이 부분에서, 당신은 가우시안 커널을 가진 SVM을 어떻게 사용하는지에 대한 실질적인 skill을 얻게 된다. ex6.m의 다음 부분은 3번째 데이터셋 (그림 6) 을 load하고 보여준다. 당신은 이 데이터셋과 함께 가우시안 커널을 가진 SVM을 사용할 것이다.\n",
    "\n",
    "제공된 데이터셋에서, ex6data3.mat, 변수 X, y, Xval, yval이 주어진다. ex6.m의 제공된 코드는 SVM 분류기를 훈련시키는데 training set (X, y)를 사용하고 dataset3Params.m 에서 로딩된 파라미터를 사용한다.\n",
    "\n",
    "당신은 작업은 cross validation set Xval, yval을 사용해서 best C와 sigma 파라미터를 결정하는 것이다. 파라미터 C와 sigma를 찾기 위해 도움이 되는 부가적인 코드를 작성해야 한다. __C와 sigma 둘 모두, 우리는 배수적인 단계로 값들을 사용할 것을 제안한다. (예를 들어, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30). 당신은 C와 sigma에 대해 모든 가능한 쌍을 시도해야 한다.__ (예를 들어, C = 0.3 그리고 sigma = 0.1) 예를 들어, C와 sigma^2 에 대해서 위에 목록화된 8개 각각을 시도한다면, (cross validation set 상에서) 결국 전체 8^2 = 64 개의 서로 다른 모델을 훈련하고 평가하게 되고 만다.\n",
    "\n",
    "best C와 sigma 파라미터를 결정한 후에, dataset3Params.m 내의 코드를 수정해서 당신이 찾은 가장 좋은 파라미터로 채워야 한다. 우리의 가장 좋은 파라미터에 대해서, SVM은 그림 7에서 보여진 것과 같이 decision boundary를 반환한다.\n",
    "\n",
    "```\n",
    "Implementation Tip: best C와 sigma 파라미터를 선택하기 위해 cross validation 을 구현할 때, cross validation set 상에서 error을 평가할 필요가 있다. 분류에 대해서, error는 올바르게 분류되지 않은 cross validation examples의 비율로 정의됨을 기억해라. Octave/MATLAB 에서, mean(double(predictions ~= yval))로 계산할 수 있다. predictions는 SVM으로 부터 모든 예측값을 포함하는 벡터이다. 그리고 yval은 cross validation set에서 나온 true label 값이다. cross validtion set 에 대해서 예측값을 생성하는 svmPredict 함수를 사용할 수 있다.\n",
    "```\n",
    "\n",
    "You should now submit your solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 코드 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spam Classification\n",
    "\n",
    "많은 이메일 서비스는 spam 필터를 제공해서 email을 스팸과 non-spmam 이메일로 높은 정확도로 분류할 수 있다. 연습문제의 이 부분에서 SVMs를 사용해서 자신만의 스팸 필터를 구축한다. \n",
    "\n",
    "주어진 이메일이 x가 스팸이면(y = 1)이거나 정상메일이라면 (y = 0) 인지를 분류하기 위해서 classifier를 훈련시킨다. 특히, 각각의 이메일을 feature 벡터 x ( Rn으로 변환할 필요가 있다. 연습문제 다음 부분에서는 그와 같은 feature 벡터가 하나의 이메일에서 어떻게 구축될 수 있는지 배우게 된다.\n",
    "\n",
    "이 연습문제의 나머지를 통해서 ex6_spam.m 스크립트를 사용하게 된다. 연습문제를 위한 데이터셋은 SpamAssassin Public Corpus의 부분집합에 기초를 두고 있다. 연습문제 목적을 위해서, 이메일의 본문만 사용하게 된다. (이메일 헤더는 제외됨)\n",
    "\n",
    "### 2.1 Preprocessing Emails\n",
    "\n",
    "그림 8: 스팸 이메일\n",
    "\n",
    "머린 러닝 작업을 시작하기 전에, 데이터넷에서 examples를 주의깊게 보는 것은 항상 도움이 된다. 그림 8은 샘플 이메일을 보여주는데 URL, 이메일 주소 (끝에), 숫자, 달러 금액등을 포함하고 있다. 만은 이메일이 비슷한 형태의 항목들을 포함하는데 (예를 들어, 숫자, 다른 URL 주소, 또는 다른 이메일 주소들) 특정 항목(예를 들어, 특정 URL 또는 특정 달러 금액)은 거의 대부분의 이메일에서 다를 것이다. 따라서, 이메일을 처리하는데 있어서 한가지 방법이 종종 채용되는데 이들 값들을 \"normalize\" \"정규화\" 하는 것이다. 그래서 모든 URL은 동일하게 처리되고 모든 숫자도 동일하게 처리된다. 예를 들어, 우리는 이메일 내의 각각의 URL을 고유 문자열 \"httpaddr\" 로 대치할 수 있다. 이렇게 해서 URL이 존재했음을 나타낸다.\n",
    "\n",
    "이것은 스팸 분류기가 분류 의사결정을 하는데, 특정 URL이 존재했는지 보다는 어떠한 URL이 존재했는지에 따라서 의사결정을 하게 해주는 효과가 있다. 이것은 전형적으로 스팸 분류기의 성능을 향상시키는데, 스패머가 종종 URL을 무작위화 시키기 때문에 어떤 특정 URL이 새로운 스팸에서 다시 볼수 있을 확률이 매우 적기 때문이다.\n",
    "\n",
    "processEmail.m 에서, 우리는 다음의 이메일 사전 작업과 정규화 단계를 구현했다.\n",
    "\n",
    "- Lower-casing: 전체 이메일은 소문자로 변환된다. 따라서 대문자는 무시된다. (예를 들어, IndIcaTE 는 Indicate와 동일하게 처리한다.\n",
    "\n",
    "- Stripping HTML: 모든 HTML 태그들은 이메일에서 제거된다. 많은 이메일이 종종 HTML 포맷으로 되어 있는데; 우리는 모든 HTML 태그를 제거하기 때문에 내용물만 남게 된다.\n",
    "\n",
    "- Normalizing URLs: 모든 URLs는 텍스트 \"httpaddr\"로 대치된다.\n",
    "\n",
    "- Normalizing Email Addresses: 모든 이메일은 텍스트 \"emailaddr\"로 대치된다.\n",
    "\n",
    "- Normalizing Numbers: 모든 숫자는 텍스트 \"number\"로 대치된다.\n",
    "\n",
    "- Normalizing Dollars: 모든 달러 표시($)는 텍스트 \"dollar\"로 대치된다.\n",
    "\n",
    "- Word Stemming: 단어들은 그들의 어간으로 축소된다. 예를 들어, \"discount\", \"discounts\", \"discounted\" 와 \"discounting\" 모두 \"discount\"로 대치된다. 때로는, Stemmer 가 끝에 있는 부가적인 글자들을 제거시키기 때문에, \"include\", \"includes\", \"included\", 그리고 \"including\" 이 모두 \"includ\" 로 대치된다.\n",
    "\n",
    "- Romoval of non-words: 단어가 아니거나 구두점은 제거된다. 모든 white spaces(탭, 개행, 빈 공란) 들은 단일 빈공란 문자로 대치된다.\n",
    "\n",
    "이들 사전처리 단계의 결과가 그림 9에 보여진다. 사전처리가 단어의 파편화와 단어가 아닌것들로 남겨놨지만, 이 형태는 feature 추출 작업에 대해서 훨씬 쉬워진다.\n",
    "\n",
    "### 2.1.1 Vocabulary List\n",
    "\n",
    "이메일을 사전처리 작업 이후에, 우리는 각각의 이메일에 대해서 단어의 목록을 갖는다. (예, 그림 9) 다음 단계는 어떤 단어를 우리의 분류기 내에서 사용하고 어떤 단어를 배제할 것인지 선택하는 것이다.\n",
    "\n",
    "이 연습문제를 위해서, 우리는 (단어 목록으로) 생각될 수 있는 단어 집합에서 가장 많이 발생한 단어들만 선택했다. __training set에 거의 드물게 나타나는 단어들은 몇몇 이메일에만 있기 때문에, 모델이 training set 에 대해서 과적합하게 만들 수 있다.__\n",
    "\n",
    "완전한 단어 목록은 파일 vocab.txt에 있고 그림 10과 같이 보여진다. 우리의 단어 목록은 최소한 스팸에서 100번 이상 나타난 모든 단어를 선택했rh 1899개의 단어 목록이 되었다. 실제로, 10,000 에서 50,000개의 단어 목록이 자주 사용된다.\n",
    "\n",
    "주어진 단어 목록으로, 우리는 사전처리된 이메일에서 각각의 단어를 단어목록에 있는 단어의 인덱스를 포함하는 단어 인덱스 목록으로 매핑시킬 수 있다. 그림 11은 샘플 이메일에 대한 매핑을 보여준다. 특히, 스팸 이메일에서, 단어 \"anyone\"은 처음 \"anyon\"으로 정규화 되고, 단어 목록의 인덱스 86번으로 매핑된다. \n",
    "\n",
    "__당신의 작업은 processEmail.m 에 있는 코드를 완성해서 이 매핑을 수행하는 것이다. 코드에서 문자열 str이 주어지는데 그것은 사전처리된 이메일에서 나온 단일 단어가 된다. 단어 목록 vocabList에서 단어들을 살펴보는데 해당 단어가 단어목록에 있는지를 찾아야 한다.__\n",
    "\n",
    "__만약 단어가 존재하면, 단어의 인덱스를 word_indices 변수에 추가한다. 만약 해당 단어가 없으면, 즉 단어 목록에 없으면, 그 단어는 생략할 수 있다.__\n",
    "\n",
    "일단, processEmail.m 를 완성하면 스크립트 ex6_spam.m은 이메일 샘플에 대해서 코드를 실행시키고 그림 9와 11과 같은 유사한 출력을 보아야 한다.\n",
    "\n",
    "```\n",
    "Octave/MATLAB Tip: Octave/MATLAB에서, 두 개의 문자열은 strcmp 함수로 비교할 수 있다. 예를 들어, strcpm(str1, str2) 는 2개의 문자열이 동일할 때만 1을 반환한다. 제공된 starter code에서, vocabList는 단어 목록에 있는 단어들을 포함하는 \"cell-array\" 이다. Octave/MATLAB에서, cell-array는 일반적인 array와 비슷하다. (예를 들어, 하나의 벡터와 같은), 한가지 예외는 cell-array의 요소는 문자열들이 될 수 있다 (일반적인 Octave/MATLAB matrix/vector에는 포함될 수 없지만). 그리고 square brackete 대신에 curly brace를 이용해서 그것들을 인덱스화 해야 한다. 특히, 인덱스 i번째의 단어를 얻기 위해서 vocabList{i}를 사용할 수 있다. length(vocabList)를 사용하면 단어내의 단어 갯수를 얻게 된다.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You should now submit your solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Extracting Features from Emails\n",
    "\n",
    "feature extraction을 구현하는데 그것은 각각의 이메일을 벡터 Rn으로 변환한다. 이 연습문제를 위해서, 당신은 단어 목록에 있는 n = # 단어수를 사용할 것이다. 특히 하나의 이메일에 대한 feature xi ( {0, 1} 는 이메일에서 발생한 사전내의 i번째 단어인지에 일치한다. 즉, xi = 1 이 되는데 만약 이메일 내의 i번째 단어가 있을 경우이고, 만약 단어가 없다면 xi = 0이 된다. 이렇게 전형적인 이메일에 대한 feature는 다음과 같다.\n",
    "\n",
    "당신은 주어진 word_indices를 가지고 emialFeatures.m 에 있는 코드를 완성해서 이메일에 대한 feature를 생성해야 한다. \n",
    "\n",
    "일단 emailFetaures.m을 구현하면, ex6_spam.m의 다음 부분은 이메일 샘플에 대해서 당신의 코드를 실행할 것이다. feature 벡터의 길이 1899개이고 45개의 non-zero 항목을 가지고 있음을 볼 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You should now submit your solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Training SVM for Spam Classification\n",
    "\n",
    "feature 추출 기능을 완성한 후에, ex6_spam.m의 다음 단계에서 사전처리된 training dataset이 로딩되어서 SVM 분류기를 훈련시키는데 사용된다. spamTrain.mat 은 4000개의 스팸과 정상메일에 대한 training examples를 포함하는데, spamTest.mat은 1000개의 test examples를 포함한다. 각각의 원본 이메일은 processEmail과 emailFeatures 기능을 사용해서 처리되었고 벡터 xi ( R1899로 변환되었다.\n",
    "\n",
    "데이터셋을 로딩한 이후에, ex6_spam.m은 SVM을 훈련시켜서 spam(y = 1)과 정상메일(y = 0)을 분류하게 된다. training이 완료되면, 분류기는 training 정확도가 약 99.8% 이고 test 정확도가 약 98.5% 임을 볼 수 있다.\n",
    "\n",
    "### 2.4 Top Predictors for Spam\n",
    "\n",
    "스팸 분류기가 어떻게 동작하는지 더 잘 이해하기 위해서, 우리는 파라미터를 조사하고 분류기가 생각하는 어떤 단어들이 가장 스팸으로 예측하는지 볼 수 있다. ex6_spam.m의 다음 단계는 분류기 내의 가장 큰 값을 가진 파라미터를 찾고 일치하는 단어를 표시한다. (그림 12).\n",
    "\n",
    "이렇게 해서, 만약 이메일이 \"guarantee\", \"remove\", \"dollar\" 그리고 \"price\"와 같은 단어를 포함하고 있다면 (그림 12에서 보여진 top predcictors), 그것은 스팸으로 분류되기 쉬울 것이다.\n",
    "\n",
    "### 2.5 Optional (ungraded) exercise: Try your own emails\n",
    "\n",
    "이제 훈련된 spam 분류기를 가졌다. 자신의 이메일을 가지고 시도해 볼 수 있다. stater code에서, 우리는 2개의 이메일 examples(emailSample1.txt와 emailSample2.txt)을 포함했고 2개의 스팸 examples(spamSample1.txt와 spamSample2.txt)을 포함했다. ex6_spam.m의 마지막 부분에서 spam 분류기를 첫번째 스팸 example에 대해서 실행시키고 학습된 SVM을 사용해서 그것을 분류한다. 우리가 제공한 다른 이메일에 대해서도 시도해보고 분류기가 올바르게 분류하는지 보아라. 당신 자신의 이메일로 시도해 볼 수도 있다. (plain text files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You do not need to submit any solutions for this optional (ungraded) exercise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Optional (ungraded) exercise: Build your own dataset\n",
    "\n",
    "이 연습문제에서, 우리는 사전처리된 training set과 test set을 제공했다. 이들 데이터넷은 당신이 이미 완성한 같은 함수(processEmail.m과 emailFeatures.m)을 통해 생성되었다. 이번 optional (ungraded) 연습문제에서, 당신은 스스로의 데이터셋을 구축하는데 SpamAssassin Public Corpus 으로부터 원본 이메일을 사용한다.\n",
    "\n",
    "여기서는 public corpus에서 원본 파일을 다운로드 받고 압축을 푼다. 압축해제 이후에 각각의 이메일에 대해서 processEmail과 emailFeatures를 실행해서 각각의 이메일에서 feature vector를 추출한다. 이것은 examples에 대한 데이터셋 X, y를 구축하게 해준다. 그리고 나서 무작위로 데이터셋을 training set과 cross validation set 그리고 test set으로 나눈다.\n",
    "\n",
    "__스스로의 dataset를 구축하면서, 우리는 당신 스스로의 단어목록을 구축해 볼것을 권장한다.(dataset에서 발생한 높은 빈도수의 단어를 선택한다.) 그리고 유용하다고 판단하는 부가 feature를 추가한다.__\n",
    "\n",
    "마지막으로, __LIBSVM과 같은 상당히 최적화된 SVM 툴박스를 시도해 볼것을 제안한다.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You do not need to submit any solutions for this optional (ungraded) exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
