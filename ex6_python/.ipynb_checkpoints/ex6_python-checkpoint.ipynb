{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Exercise 6: Support Vector Machines\n",
    "\n",
    "```\n",
    "by Seokkyu Kong\n",
    "Date: 2016-03-28\n",
    "Summary: Coursera 코세라 machine learning 기계학습 강의 연습문제 6번을 Octave에서 Python으로 code migration 한다.\n",
    "```\n",
    "\n",
    "## Introduction \n",
    "\n",
    "이번 연습문제에서는, support vector machines 지지 벡터 머신 (SVMs) 를 사용해서 스팸 분류기를 구축한다. \n",
    "\n",
    "## 1. Support Vector Machines\n",
    "\n",
    "연습문제 전반부에서, 다양한 example 2D datasets을 가지고 지지 벡터 머신을 사용한다. 이들 데이터셋으로 실험하는 것은 SVM이 어떻게 동작하는지와 SVMs에 가우시안 커널을 어떻게 사용하는지에 대한 직관을 얻는데 도움이 될 것이다. 연습문제 후반부에서는 스팸 분류기를 구축하기 위해서 지지 벡터 머신을 사용할 것이다. \n",
    "\n",
    "### 1.1 Example Dataset 1\n",
    "\n",
    "우리는 2D example dataset으로 시작하는데, linear boundary로 분리될 수 있다. 스크립트 ex6.m 은 training data를 plot한다. (그림 1) 이 데이터넷에서, positive examples(+로 표시됨)의 위치와 negative exampels(o로 표시됨)의 위치는 gap에 의해서 표시된 자연스럼 구분을 제시한다. 그런데, 왼쪽 끝에 (0.1, 4.1) 위치에서 이상치 positive example + 가 있음을 주목해라. 이 연습문제의 일부분으로, 이 이상치가 SVM decision boundary에 어떻게 영향을 주는지 보게 될 것이다.\n",
    "\n",
    "연습문제 이 부분에서, SVMs에 서로 다른 C 값을 사용하게 될 것이다. 비공식적으로, __파라미터 C는 잘못 분류된 traininig examples에 대한 penalty를 제어하는 양의 값이다. 값이 큰 C 파라미터는 SVM이 모든 examples를 올바르게 분류하도록 시킨다. C는 1/lambda 와 유사한 역할을 하는데, lambda는 logistic regression을 위해서 이전에 사용했던 regularization 파라미터이다.__\n",
    "\n",
    "ex6.m의 다음 부분에서 SVM 소프트웨어를 이용해서 (C = 1)로 SVM을 훈련시키는데, 우리는 시작하는 코드로 svmTrain.m 을 포함시켰다. \n",
    "\n",
    "C  = 1 일때, SVM은 두 개의 데이터셋 사이에 있는 gap 에 decision boundary를 놓는데 왼쪽 구성에 있는 데이터 포인트는 잘못 분류하고 있음을 볼 수 있다. (그림 2)\n",
    "\n",
    "```\n",
    "Implementation Note: 대부분의 SVM 소프트웨어 패키지들은 (svmTrain.m을 포함해서) 자동적으로 추가적인 feature x0 = 1을 추가한다. 그리고 자동적으로 절편 항목 theta0를 학습하는데 신경을 쓴다. 그래서 traininig data를 SVM 소프트웨어에 전달할 때, 추가 feature인 x0 = 1을 추가할 필요가 없다. 특히, Octave/MATLAB 에서 코드는 traininig examples x ( Rn 에서 동작해야 한다. (x ( Rn+1 이 아니다); 예를 들어 첫번째 exmaple dataset은 x ( R2 이다.\n",
    "```\n",
    "\n",
    "당신의 작업은 이 데이터넷 상에서 서로 다른 C 값을 시도해보는 것이다. 특히, 스크립트 내의 C 값을 C = 100으로 하고 SVM training을 다시 실행해 봐라. C = 100 일때, SVM은 이제 각각의 단일 example을 올바르게 분류하지만, decision boundary는 데이터에 대해서 자연스럽게 맞지 않음을 볼 수 있어야 한다.\n",
    "\n",
    "### 1.2 SVM with Gaussian Kernels\n",
    "\n",
    "연습문제의 이 부분에서, 당신은 non-linear classification을 수행하는 SVMs를 사용하게 된다. 특히, 가우시안 커널을 가진 SVMs을 선형으로 분리될 수 없는 데이터셋 상에 사용할 것이다.\n",
    "\n",
    "#### 1.2.1 Gaussian Kernel\n",
    "\n",
    "SVM으로 non-linear decision boundaries를 찾기 위해서는, 우리는 먼저 Gaussian kernel을 구현할 필요가 있다. __가우시안 커널을 한 쌍의 examples 사이에 \"distance\"를 측정하는 유사도 함수로 생각할 수 있다. 가우시안 커널은 또한 bandwidth 파라미터 sigma로 파라미터화 할 수 있는데 그것은 examples가 멀리 떨어짐에 따라 얼마나 빨리 유사도 메트릭이 감소되는지 (0으로) 결정하는 값이다.__\n",
    "\n",
    "당신은 이제 gaussianKernel.m 을 완성해서 2개의 examples (x(i), x(j)) 사이의 Gaussian kernel을 계산해야 한다. 가우시안 커널 함수는 다음처럼 정의 된다.\n",
    "\n",
    "일단, gaussianKernel.m 함수를 완성하면, 스크립트 ex6.m은 커널 함수를 2개의 제공된 examples에 테스트 하는데 0.324652 값을 기대해야 한다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 코드 작성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1.2.2 Example Dataset 2\n",
    "\n",
    "ex6.m의 다음 부분은 dataset 2를 load하고 plot 할 것이다. (그림 4) 이 그림에서, 당신은 이 데이터셋에 대한 positive와 negative examples를 분리하는 linear boundary가 없음을 볼 수 있다. 어쨌든, SVM과 함께 가우시안 커널을 이용해서 데이터셋에 합리적으로 잘 성능을 낼 수 있는 비선형 decision boundary를 학습할 수 있게 된다. \n",
    "\n",
    "만약 가우시안 함수를 올바르게 구현했다면, ex6.m은 이 데이터셋 상에서 가우시안 커널을 가진 SVM을 훈련시키게 된다.\n",
    "\n",
    "Figure 5: SVM (Gaussian Kernel) Decision Boundary (Example Dataset 2)\n",
    "\n",
    "그림 5는 가우시안 커널을 가진 SVM에 의해 발견된 decision boundary를 보여준다. decision boundary는 대부분의 positive와 negative examples를 올바르게 분리할 수 있고 데이터셋의 contours에 잘 따른다.\n",
    "\n",
    "#### 1.2.3 Example Dataset 3\n",
    "\n",
    "연습문제 이 부분에서, 당신은 가우시안 커널을 가진 SVM을 어떻게 사용하는지에 대한 실질적인 skill을 얻게 된다. ex6.m의 다음 부분은 3번째 데이터셋 (그림 6) 을 load하고 보여준다. 당신은 이 데이터셋과 함께 가우시안 커널을 가진 SVM을 사용할 것이다.\n",
    "\n",
    "제공된 데이터셋에서, ex6data3.mat, 변수 X, y, Xval, yval이 주어진다. ex6.m의 제공된 코드는 SVM 분류기를 훈련시키는데 training set (X, y)를 사용하고 dataset3Params.m 에서 로딩된 파라미터를 사용한다.\n",
    "\n",
    "당신은 작업은 cross validation set Xval, yval을 사용해서 best C와 sigma 파라미터를 결정하는 것이다. 파라미터 C와 sigma를 찾기 위해 도움이 되는 부가적인 코드를 작성해야 한다. __C와 sigma 둘 모두, 우리는 배수적인 단계로 값들을 사용할 것을 제안한다. (예를 들어, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30). 당신은 C와 sigma에 대해 모든 가능한 쌍을 시도해야 한다.__ (예를 들어, C = 0.3 그리고 sigma = 0.1) 예를 들어, C와 sigma^2 에 대해서 위에 목록화된 8개 각각을 시도한다면, (cross validation set 상에서) 결국 전체 8^2 = 64 개의 서로 다른 모델을 훈련하고 평가하게 되고 만다.\n",
    "\n",
    "best C와 sigma 파라미터를 결정한 후에, dataset3Params.m 내의 코드를 수정해서 당신이 찾은 가장 좋은 파라미터로 채워야 한다. 우리의 가장 좋은 파라미터에 대해서, SVM은 그림 7에서 보여진 것과 같이 decision boundary를 반환한다.\n",
    "\n",
    "```\n",
    "Implementation Tip: best C와 sigma 파라미터를 선택하기 위해 cross validation 을 구현할 때, cross validation set 상에서 error을 평가할 필요가 있다. 분류에 대해서, error는 올바르게 분류되지 않은 cross validation examples의 비율로 정의됨을 기억해라. Octave/MATLAB 에서, mean(double(predictions ~= yval))로 계산할 수 있다. predictions는 SVM으로 부터 모든 예측값을 포함하는 벡터이다. 그리고 yval은 cross validation set에서 나온 true label 값이다. cross validtion set 에 대해서 예측값을 생성하는 svmPredict 함수를 사용할 수 있다.\n",
    "```\n",
    "\n",
    "You should now submit your solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 코드 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spam Classification\n",
    "\n",
    "많은 이메일 서비스는 spam 필터를 제공해서 email을 스팸과 non-spmam 이메일로 높은 정확도로 분류할 수 있다. 연습문제의 이 부분에서 SVMs를 사용해서 자신만의 스팸 필터를 구축한다. \n",
    "\n",
    "주어진 이메일이 x가 스팸이면(y = 1)이거나 정상메일이라면 (y = 0) 인지를 분류하기 위해서 classifier를 훈련시킨다. 특히, 각각의 이메일을 feature 벡터 x ( Rn으로 변환할 필요가 있다. 연습문제 다음 부분에서는 그와 같은 feature 벡터가 하나의 이메일에서 어떻게 구축될 수 있는지 배우게 된다.\n",
    "\n",
    "이 연습문제의 나머지를 통해서 ex6_spam.m 스크립트를 사용하게 된다. 연습문제를 위한 데이터셋은 SpamAssassin Public Corpus의 부분집합에 기초를 두고 있다. 연습문제 목적을 위해서, 이메일의 본문만 사용하게 된다. (이메일 헤더는 제외됨)\n",
    "\n",
    "### 2.1 Preprocessing Emails\n",
    "\n",
    "그림 8: 스팸 이메일\n",
    "\n",
    "머린 러닝 작업을 시작하기 전에, 데이터넷에서 examples를 주의깊게 보는 것은 항상 도움이 된다. 그림 8은 샘플 이메일을 보여주는데 URL, 이메일 주소 (끝에), 숫자, 달러 금액등을 포함하고 있다. 만은 이메일이 비슷한 형태의 항목들을 포함하는데 (예를 들어, 숫자, 다른 URL 주소, 또는 다른 이메일 주소들) 특정 항목(예를 들어, 특정 URL 또는 특정 달러 금액)은 거의 대부분의 이메일에서 다를 것이다. 따라서, 이메일을 처리하는데 있어서 한가지 방법이 종종 채용되는데 이들 값들을 \"normalize\" \"정규화\" 하는 것이다. 그래서 모든 URL은 동일하게 처리되고 모든 숫자도 동일하게 처리된다. 예를 들어, 우리는 이메일 내의 각각의 URL을 고유 문자열 \"httpaddr\" 로 대치할 수 있다. 이렇게 해서 URL이 존재했음을 나타낸다.\n",
    "\n",
    "이것은 스팸 분류기가 분류 의사결정을 하는데, 특정 URL이 존재했는지 보다는 어떠한 URL이 존재했는지에 따라서 의사결정을 하게 해주는 효과가 있다. 이것은 전형적으로 스팸 분류기의 성능을 향상시키는데, 스패머가 종종 URL을 무작위화 시키기 때문에 어떤 특정 URL이 새로운 스팸에서 다시 볼수 있을 확률이 매우 적기 때문이다.\n",
    "\n",
    "processEmail.m 에서, 우리는 다음의 이메일 사전 작업과 정규화 단계를 구현했다.\n",
    "\n",
    "- Lower-casing: 전체 이메일은 소문자로 변환된다. 따라서 대문자는 무시된다. (예를 들어, IndIcaTE 는 Indicate와 동일하게 처리한다.\n",
    "\n",
    "- Stripping HTML: 모든 HTML 태그들은 이메일에서 제거된다. 많은 이메일이 종종 HTML 포맷으로 되어 있는데; 우리는 모든 HTML 태그를 제거하기 때문에 내용물만 남게 된다.\n",
    "\n",
    "- Normalizing URLs: 모든 URLs는 텍스트 \"httpaddr\"로 대치된다.\n",
    "\n",
    "- Normalizing Email Addresses: 모든 이메일은 텍스트 \"emailaddr\"로 대치된다.\n",
    "\n",
    "- Normalizing Numbers: 모든 숫자는 텍스트 \"number\"로 대치된다.\n",
    "\n",
    "- Normalizing Dollars: 모든 달러 표시($)는 텍스트 \"dollar\"로 대치된다.\n",
    "\n",
    "- Word Stemming: 단어들은 그들의 어간으로 축소된다. 예를 들어, \"discount\", \"discounts\", \"discounted\" 와 \"discounting\" 모두 \"discount\"로 대치된다. 때로는, Stemmer 가 끝에 있는 부가적인 글자들을 제거시키기 때문에, \"include\", \"includes\", \"included\", 그리고 \"including\" 이 모두 \"includ\" 로 대치된다.\n",
    "\n",
    "- Romoval of non-words: 단어가 아니거나 구두점은 제거된다. 모든 white spaces(탭, 개행, 빈 공란) 들은 단일 빈공란 문자로 대치된다.\n",
    "\n",
    "이들 사전처리 단계의 결과가 그림 9에 보여진다. 사전처리가 단어의 파편화와 단어가 아닌것들로 남겨놨지만, 이 형태는 feature 추출 작업에 대해서 훨씬 쉬워진다.\n",
    "\n",
    "### 2.1.1 Vocabulary List\n",
    "\n",
    "이메일을 사전처리 작업 이후에, 우리는 각각의 이메일에 대해서 단어의 목록을 갖는다. (예, 그림 9) 다음 단계는 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
