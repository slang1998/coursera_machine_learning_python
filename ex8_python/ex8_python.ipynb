{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Programming Exercise 8: Anomaly Detection and Recommender Systems\n",
    "\n",
    "```\n",
    "by Seokkyu Kong\n",
    "Date: 2016-04-13\n",
    "Summary: Coursera 코세라 machine learning 기계학습 강의 연습문제 8번을 Octave에서 Python으로 code migration 한다.\n",
    "```\n",
    "\n",
    "## Introduction\n",
    "\n",
    "이번 연습문제에서는, __anomaly detection algorithm 이상치 검출 알고리즘을 구현하고__ 네트워크 상에서 오동작 하는 서버들을 검출하기 위해 적용해볼 것이다. 2번째 부분에서, __영화 추천 시스템을 구축하기 위해 collaborative filtering 협업 필터링을__ 사용하게 된다.\n",
    "\n",
    "연습문제 첫번째 부분 (이상치 검출)을 통해서 스크립트 ex8.m을 사용하게 된다. 협업 필터링 2번째 부분에서는 ex8_cofi.m을 사용하게 된다. 이들 스크립트는 문제를 위한 데이터셋을 준비하고 당신이 작성한 함수들을 호출한다. 과제 내의 지시를 따르면서, 다른 파일에 있는 함수들만 수정해야 한다. \n",
    "\n",
    "## 1. Anomaly detection\n",
    "\n",
    "연습문제에서, 이상치 검출 알고리즘을 작성하고 서버 컴퓨터에 비정상 행위를 검출한다. 이들 feature는 각각 서버의 throughput (mb/s)와 latency (ms) 를 측정한다. 서버가 동작중일때, 서버가 어떻게 행동하는지에 대한 m = 307 examples를 수집한다. 그리고 이것은 라벨이 없는 데이터셋 $ \\{x^{(1)},,,x^{(m)} \\} $ 이 된다. 당신은 이들 examples의 대다수가 \"normal\" (non-anomalous) 정상적으로 동작하는 서버의 exmaples이고, 데이터셋 내에 비정상적으로 행동하는 서버의 몇몇 예제들이 있을 수 있다고 의심한다.\n",
    "\n",
    "__가우시안 모델을 이용해서 데이터셋 내의 비정상 examples를 검출하게 될 것이다.__ 먼저 2D 데이터셋에서 시작하는데 그것은 알고리즘이 하는 것을 가시화하게끔 만들어 준다. __그 데이터넷 상에서, 가우시안 분포를 fit하게 되고 장애로 생각될 수 있는 매우 낮은 확률을 가진 값을 찾는다. 그리고 난다음, 많은 차원을 가진 더 큰 데이터셋에 이상치 검출 알고리즘을 적용한다.__\n",
    "\n",
    "ex8.m의 첫 부분에서 그림 1에 보여진 것과 같이 데이터셋을 가시화한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.1 Gaussian distribution\n",
    "\n",
    "__이상치 검출을 수행하기 위해서, 데이터의 분포에 모델을 fit 적합시킬 필요가 있다.__\n",
    "\n",
    "__주어진 training set {x(1),,, x(m)} ( $ x^{(i)} \\in \\mathbb{R}^{n} $ ), 에서 x(i)에 대한 각각의 feature에 대한 가우시안 분포를 측정하고 싶어할 것이다.__ 각각의 feature i = 1,,,n 에 대해서 파라미터 $ \\mu _{i} $ , $ \\sigma _{i}^2 $을 찾을 필요가 있고 그것은 i번째 차원의 데이터 $ \\{ x_{i} ^{(1)}, ,,, x_{i} ^{(m)} \\} $ 에 fit 하게 된다. (각 example에서의 i번째 차원)\n",
    "\n",
    "가우시안 분포는 다음과 같이 주어진다.\n",
    "\n",
    "여기서 $ \\mu $ 는 평균이고 $ \\sigma^2 $ 은 분산을 제어한다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Estimating parameters for a Gaussian\n",
    "\n",
    "i-번째 feature에 대한 파라미터 $ ( \\mu_{i}, \\sigma^{2} ) $ 를 평가할 수 있는데 다음 방정식을 사용한다. 평균을 계산하기 위해서 아래처럼 사용한다.\n",
    "\n",
    "(1)\n",
    "\n",
    "그리고 분산에 대해서는 아래처럼 사용한다.\n",
    "\n",
    "(2)\n",
    "\n",
    "당신의 작업은 __estimateGaussian.m__ 내의 코드를 완성하는 것이다. 이 함수는 데이터 행렬 X를 입력으로 가지며 n 차원이 벡터 mu를 출력하는데 모든 n개 feature에 대한 평균을 담고 있다. 그리고 다른 n차원의 벡터 simga2를 출력하는데 모든 features에 대한 분산을 가지고 있다. \n",
    "\n",
    "이것을 각 feature와 각 example에 대해서 for-loop를 사용할 수 있다 (비록 벡터화 구현이 더욱 효율적이고, 만약 좋아한다면 벡터화 구현을 사용해보아라). __Octave/MATLAB에서 var 함수는 $ \\sigma^{2} $을 계산할 때, 1/m 대신에 (기본적으로) 1/(m-1)을 사용한다.__\n",
    "\n",
    "일단 estimateGaussian.m의 코드를 완성한 이후, ex8.m의 다음 부분은 fitted 가우시안 분포의 contours를 가시화 할 것이다. 당신은 그림 2와 유사한 plot을 얻어야 한다. 당신의 plot에서, 대부분의 examples가 가장 높은 확률을 가진 영역에 있음을 볼 수 있다. 반면 anomalous exampes 비정상 예제들은 낮은 확률을 가진 영역에 있다.\n",
    "\n",
    "Figure 2: The Gaussian distribution contours of the distribution fit to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You should now submit your solutions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Selecting the threshold, $ \\varepsilon $\n",
    "\n",
    "이제 당신은 가우시안 파라미터를 평가했다. 당신은 어떤 examples가 매우 높은 확률을 갖는지 주어진 분포에서 조사할 수 있고 어떤 examples가 매우 낮은 확률을 갖는지 알 수 있다. **낮은 확률의 examples는 우리의 데이터셋에서 더욱 비정상일 가능성이 있다.** **어떤 examples가 비정상인지 결정하는 한 가지 방법은 cross validation 을 기초로 threshold를 선택하는 것이다.** \n",
    "\n",
    "연습문제의 이 부분에서는, **알고리즘을 구현해서 threshold $ \\varepsilon $ 을 선택하는데 cross validation 상에서 F1 score를 사용한다.**\n",
    "\n",
    "당신은 이제 selectThreshold.m 내의 코드를 완성해야 한다. 이것을 위해서, 우리는 cross validation set {(Xcv^(1), ycv^(1)),,,,(xcv^(mcv), ycv^(mcv))}, 를 사용한다. 여기서 label y = 1은 비정상 example과 일치한다. y = 0은 정상 example이다. 각각의 cross validtion example에 대해서, 우리는 p(xcv^(i))를 계산한다. 이들 확률에 대한 모든 벡터 p(xcv^(1)),,,p(xcv^(mcv))는 pval 벡터로 selectThreshold.m에 전달된다. 일치하는 라벨 ycv^(1),,,ycv^(mcv) 는 동일한 함수에 yval 벡터로 전달된다.\n",
    "\n",
    "함수 selectThreshold.m은 2개의 값을 반환해야 하는데, 첫번째는 선택된 threshold $ \\varepsilon $ 이다. **만약 하나의 example x가 낮은 확률 p(x) < $ \\varepsilon $ 이라면, 그것은 비정상으로 생각될 수 있다.** 함수는 또한 ** $ F_1 $ score를 반환해야 하는데, 그것은 주어진 어떤 threshold 상에서 정말 비정상을 얼마나 잘 발견할 지에 대해서 이야기 해준다.**\n",
    "\n",
    "서로 다른 많은 $ \\varepsilon $ 에 대해서, 당신은 F1 score를 계산하는데, 현재의 threshold 가 얼마나 많은 examples를 정상과 비정상으로 분류하는지 계산한다.\n",
    "\n",
    "F1 score는 precision (prec)과 recall (rec) 을 사용해서 계산된다.\n",
    "\n",
    "F1 = (2 * prec * rec) / (prec + rec) .... (3)\n",
    "\n",
    "precision과 recall은 다음처럼 계산한다:\n",
    "\n",
    "prec = tp / (tp + fp) .... (4)\n",
    "\n",
    "rec = tp / (tp + fn) .... (5)\n",
    "\n",
    "여기서\n",
    "- tp 는 true positives의 갯수이다: ground truth label이 비정상이고 우리의 알고리즘도 그것을 비정상으로 분류했다.\n",
    "- fp 는 false positives 갯수이다:ground truth label이 anomaly가 아니라고 말하지만, 우리의 알고리즘은 anomaly로 올바르지 않게 분류했다.\n",
    "- fn 은 false negatives의 개수이다: ground truth label은 anomaly라고 말하지만, 우리의 알고리즘은 anomaly가 아니라고 올바르지 않게 분류했다.\n",
    "\n",
    "제공된 코드 selectThreshold.m에서, 서로 다른 e 값을 시도해보고 F1 score 기준으로 가장 좋은 e를 선택하는 loop가 이미 있다. 당신은 모든 cross validation examples에 대해서 for-llp를 사용해 F1 score를 계산하는 부분을 구현할 수 있다. (tp, fp, fn 의 값을 계산한다.). epsilon이 약 8.99e-05 정도임을 보아야 한다.\n",
    "\n",
    "Implementation Note: tp, fp 그리고 fn을 계산하기 위해서, 모든 examples에 대해 loop 보다는 벡터화된 구현을 사용할 수 있을 것이다. 이것은 Octave/MATLAB의 벡터와 숫자 사이의 동일성 테스트를 통해 구현될 수 있다. 만약 몇몇 이진값이 n-차원 binary 벡터로 v \\in {0, 1}^n 이라면, 이 벡터 안에 얼마나 많은 0이 있는지는 **sum(v == 0)**을 사용해서 알 수 있다.\n",
    "또한 논리 연산자 and 를 그와 같은 binary vector에 적용할 수 있다. 예를 들어, cvPredictions 가 cross validation set의 크기로 된 binary vector라고 하자. 여기서 i-번째 요소가 1이고 알고리즘이 xcv^(i)를 anomaly로 보고 0은 그렇지 않다고 하자. 그러면, 예를 들어, false positives 숫자 계산은 **fp = sum((cvPredictions == 1) & (yval == 0))**을 사용해서 가능한다.\n",
    "\n",
    "Figure 3: The classified anomailes.\n",
    "\n",
    "일단 selectThreshold.m 의 코드를 완성하면, ex8.m의 다음 단계는 당신의 anomaly 검출 코드를 실행시켜서 plot 내의 anomalies에 원을 그릴 것이다. (그림 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You should now submit your solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 High dimensional dataset\n",
    "\n",
    "스크립트 ex8.m의 마지막 부분은 당신이 구현한 비정상 검출 알고리즘을 실행시키는데 더욱 현실적이고 더욱 어려운 dataset으로 작업한다. 이 데이터셋에서, 각 example은 11개의 feature로 설명되는데, 서버들에 대한 많은 속성을 가지고 있다.\n",
    "\n",
    "스크립트는 가우시안 파라미터를 평가하기 위해 당신의 코드를 사용한다. (mu_i and sigma^2). 그리고 가우시안 파라미터를 평가한 training data X와 cross-validation set Xval 2가지 모두에 대한 확률을 평가한다. 마지막으로, selectThreshold를 사용하는데 가장 좋은 threshold e를 찾는다. 대략 epsilon 값이 1.38e-18 정도이고, 117개의 anomalies를 찾은 것을 보게 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recommender Systems\n",
    "\n",
    "이번 연습문제에서는, collaborative filtering 협업 필터링 학습 알고리즘을 구현하고 영화 평가 데이터셋에 적용해본다. 이 데이터셋은 1에서 5까지의 scale로 된 평가 점수로 구성된다. 데이터셋은 n_u = 943개의 사용자를 가지고 있고 n_m = 1682 개의 영화를 가지고 있다. 연습문제 이 부분에서, 스크립트 ex8_cofi.m을 가지고 작업하게 될 것이다.\n",
    "\n",
    "연습문제 다음 부분에서는, 함수 cofiCostFunc.m을 구현하는데 협업 필터링의 objective 함수와 gradient를 계산한다. cost 함수와 gradient를 구현한 이후에, fmincg.m 을 사용해서 협업 필터링에 대한 파라미터를 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Movie ratings dataset\n",
    "\n",
    "스크립트 ex8_cofi.m의 첫 부분은 데이터셋 ex8_movies.mat를 로드하고 변수 Y와 R을 제공한다.\n",
    "\n",
    "**행렬 Y (num_movies x num_users 행렬) 은 평가점수 y^(i, j)를 저장한다. (1에서 5까지). 행렬 R은 이진값으로 된 indicator 행렬인데, R(i, j) = 1 이라면 user j가 영화 i에 평가 점수를 주었다는 것이고, R(i, j) = 0 이라면 영화에 대한 평가점수를 주지 않았다는 것이다.**\n",
    "\n",
    "**협업 필터링의 목적은 사용자가 아직 평가하지 않은 영화에 대해서 영화 평점을 예측하는 것이다. 즉, R(i, j) = 0 인 항목에 대해서 말이다. 이것은 사용자에게 가장 높게 예측된 평점을 가진 영화들을 추천할 수 있게 해준다.**\n",
    "\n",
    "행렬 Y에 대한 이해를 돕기 위해서, 스크립트 ex8_cofi.m은 첫번째 영화(Toy Story)에 대한 영화 평점 평균을 계산하고 평균 평점을 화면에 출력한다.\n",
    "\n",
    "연습문제 이 부분을 통해서, 행렬 X와 Theta를 가지고 작업하게 될 것이다.\n",
    "\n",
    "\n",
    "**X의 i-번째 행은 i-번째 영화에 대한 feature 벡터 x^(i) 에 일치한다. 그리고 Theta의 j-번째 행은 j-번째 사용자에 대한 파라미터 벡터 theta^(j)에 일치한다.**\n",
    "\n",
    "x^(i)와 theta^(j) 모두 n-차원 벡터이다. 연습문제의 목적을 위해서, 당신은 n = 100을 사용할 것이고 그래서 x^(i) %in R^100 이 된다. 그리고 theta^(j) %in R^100 이 된다.\n",
    "\n",
    "따라서 X 는 n_m x 100 행렬이 되고 Theta 는 n_u x 100 행렬이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Collaborative filtering learning algorithm\n",
    "\n",
    "이제, 협업 필터링 알고리즘을 구현하게 된다. **먼저 (regularization 이 없는) cost function으로 시작한다.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
